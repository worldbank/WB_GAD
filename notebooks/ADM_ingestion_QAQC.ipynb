{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA/QC for delivered administrative boundaries\n",
    "The World Bank receives regular deliveries of official administrative boundaries. This script will process and evaluate these boundaries in several ways:\n",
    "\n",
    "- Combine the two ID columns into a single, primary key  \n",
    "  a. Check to ensure no duplicates in this new, primary key\n",
    "- Combine ADM0 file with disputed areas shapefile \n",
    "- Create ocean mask \n",
    "- Within higher heirarchical level, evaluate name duplication\n",
    "- Perform topological checks  \n",
    "  a. Ensure no overlaps  \n",
    "  b. Ensure no gaps  \n",
    "  c. Ensure all admin1 and admin2 shapes are fully contained within their heirarchical parents\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.geometry import Point, Polygon, box, shape\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from wb_gad_helper import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_folder = r'C:\\WBG\\Work\\data\\ADMIN\\NEW_WB_BOUNDS'\n",
    "out_folder = r'C:\\WBG\\Work\\data\\ADMIN\\QAQC'\n",
    "better_formats_folder = r'C:\\WBG\\Work\\data\\ADMIN\\BETTER_FORMATS'\n",
    "if not os.path.exists(better_formats_folder):\n",
    "    os.makedirs(better_formats_folder)\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "admin0_file = os.path.join(admin_folder, 'WB_GAD_ADM0.shp')\n",
    "adm0_disputes_file = os.path.join(admin_folder, 'WB_GAD_NDLSA.shp')\n",
    "admin1_file = os.path.join(admin_folder, 'WB_GAD_ADM1.shp')\n",
    "admin2_file = os.path.join(admin_folder, 'WB_GAD_ADM2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add World Bank classifications to ADM0\n",
    "wb_classes = get_wb_classifications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_type\n",
       "REGION       1100\n",
       "REGION_UN     982\n",
       "OTHER         878\n",
       "LENDING       675\n",
       "INCOME        565\n",
       "CONTINENT     206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_classes['group_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "002    60\n",
       "ECS    58\n",
       "150    51\n",
       "142    50\n",
       "TSS    48\n",
       "SSF    48\n",
       "SSA    47\n",
       "LCN    42\n",
       "DSS    39\n",
       "EAS    38\n",
       "TLA    30\n",
       "009    29\n",
       "AFE    26\n",
       "LAC    23\n",
       "TEC    23\n",
       "TEA    23\n",
       "EAP    23\n",
       "ESA    22\n",
       "ARB    22\n",
       "BLA    22\n",
       "AFW    22\n",
       "MEA    21\n",
       "MCT    21\n",
       "ECA    20\n",
       "BEC    19\n",
       "005    16\n",
       "WAF    16\n",
       "MPA    15\n",
       "DEA    14\n",
       "CMD    13\n",
       "MNA    13\n",
       "TMN    12\n",
       "PAC    10\n",
       "SER    10\n",
       "CFR     9\n",
       "BMN     9\n",
       "SEA     9\n",
       "BEA     9\n",
       "BSS     9\n",
       "CRB     8\n",
       "MDE     8\n",
       "SAM     8\n",
       "SAS     8\n",
       "DLA     8\n",
       "TSA     8\n",
       "CAM     7\n",
       "SAX     7\n",
       "DSA     7\n",
       "CAT     6\n",
       "CAS     5\n",
       "CNA     5\n",
       "EER     5\n",
       "NAF     5\n",
       "DEC     4\n",
       "DMN     3\n",
       "NAC     3\n",
       "ESS     3\n",
       "BSA     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_classes.loc[wb_classes['group_type'] == 'REGION']['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm0 = gpd.read_file(admin0_file)\n",
    "adm0_disputes = gpd.read_file(adm0_disputes_file)\n",
    "adm1 = gpd.read_file(admin1_file)\n",
    "adm2 = gpd.read_file(admin2_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_adm1 = merge_id_columns(adm1, [['P_CODE_1', 'P_CODE_1_t'], ['ADM1CD', 'ADM1CD_t']])\n",
    "merged_adm2 = merge_id_columns(adm2, [['P_CODE_1', 'P_CODE_1_t'], ['P_CODE_2', 'P_CODE_2_t'], ['ADM1CD', 'ADM1CD_t'], ['ADM2CD', 'ADM2CD_t']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADM1CD_c duplicates: 0\n",
      "ADM2CD_c duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in ADM1\n",
    "test_col = 'ADM1CD_c'\n",
    "check_duplicates(merged_adm1, test_col, os.path.join(out_folder, f'adm1_duplicates_{test_col}.gpkg'))\n",
    "\n",
    "# Check for duplicates in ADM2\n",
    "test_col = 'ADM2CD_c'\n",
    "check_duplicates(merged_adm2, test_col, os.path.join(out_folder, f'adm2_duplicates_{test_col}.gpkg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ADM0 with disputed territories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in adm0_disputes.columns:\n",
    "    if not col in adm0.columns:\n",
    "        adm0_disputes.drop(columns=[col], inplace=True)\n",
    "adm0_disputes.head()\n",
    "adm0_complete = pd.concat([adm0, adm0_disputes], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a global ocean mask from the admin divisions\n",
    "ocean_polygon = box(-180, -90, 180, 90)  # Global bounding box for ocean\n",
    "#clip ocean polygon to adm0 boundaries\n",
    "ocean_polygon = ocean_polygon.difference(adm0_complete.union_all())  # Remove land areas\n",
    "ocean_mask = gpd.GeoDataFrame([[1, ocean_polygon]], columns=['id', 'geometry'], crs=4326)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate name duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate duplicate names in adm1 and adm2\n",
    "evaluate_duplicate_names(merged_adm1, 'NAM_1', 'ISO_A3', os.path.join(out_folder, \"ADM1_name_duplicates.log\"))\n",
    "# Evaluate duplicate names in adm1 and adm2\n",
    "evaluate_duplicate_names(merged_adm2, 'NAM_2', 'ADM1CD_c', os.path.join(out_folder, \"ADM2_name_duplicates.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsj = gpd.sjoin(adm0, adm0, how=\"inner\", predicate=\"overlaps\", lsuffix=\"left\", rsuffix=\"right\")\\nsj = sj[sj.index != sj.index_right]\\n\\nsj[\\'intersection_geom\\'] = sj[\\'geometry_left\\'].intersection(sj[\\'geometry_right\\'])\\nsj[\\'intersection_area\\'] = sj[\\'intersection_geom\\'].area\\nsj\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use sjoin to identify overlapping polygons\n",
    "'''\n",
    "sj = gpd.sjoin(adm0, adm0, how=\"inner\", predicate=\"overlaps\", lsuffix=\"left\", rsuffix=\"right\")\n",
    "sj = sj[sj.index != sj.index_right]\n",
    "\n",
    "sj['intersection_geom'] = sj['geometry_left'].intersection(sj['geometry_right'])\n",
    "sj['intersection_area'] = sj['intersection_geom'].area\n",
    "sj\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate datasets into primary and secondary tables\n",
    "\n",
    "The delivered files contain several columns that are temporary or reference external sources. This section will separate the superfluous columns into a secondary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_out_folder = os.path.join(better_formats_folder, 'simplified_output')\n",
    "if not os.path.exists(simplified_out_folder):\n",
    "    os.makedirs(simplified_out_folder)\n",
    "adm1_primary = 'ADM1CD_c'\n",
    "adm1_simple_cols = ['ISO_A3','ISO_A2','WB_A3','WB_REGION','WB_STATUS','NAM_0','NAM_1','ADM1CD_c','GEOM_SRCE', 'geometry']\n",
    "adm1_bad_cols = [adm1_primary] + [x for x in merged_adm1.columns if x not in adm1_simple_cols]\n",
    "\n",
    "adm2_primary = 'ADM2CD_c'\n",
    "adm2_simple_cols = adm1_simple_cols + ['NAM_2','ADM2CD_c']\n",
    "adm2_bad_cols = [adm2_primary] + [x for x in merged_adm2.columns if x not in adm2_simple_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out final versions in several data formats\n",
    "\n",
    "write out:\n",
    "- adm0 base\n",
    "- adm0 NDLSA\n",
    "- adm0 complete\n",
    "- adm1 simple\n",
    "- adm1 supplemntal columns\n",
    "- adm2 simple \n",
    "- adm2 supplemental columns\n",
    "\n",
    "in these formats\n",
    "- geopackage\n",
    "- geojson\n",
    "- shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_folder = os.path.join(admin_folder, 'FOR_PUBLICATION')\n",
    "if not os.path.exists(final_folder):\n",
    "    os.makedirs(final_folder)\n",
    "for file_format in ['gpkg', 'shp', 'geojson']:\n",
    "    temp_folder = os.path.join(final_folder, file_format)\n",
    "    if not os.path.exists(temp_folder):\n",
    "        os.makedirs(temp_folder)\n",
    "\n",
    "for file_def in [\n",
    "    (ocean_mask, 'WB_GAD_ocean_mask'),\n",
    "    (adm0_complete, 'WB_GAD_ADM0_complete'),\n",
    "    (adm0, 'WB_GAD_ADM0'),\n",
    "    (adm0_disputes, 'WB_GAD_ADM0_NDLSA'),\n",
    "    (merged_adm1.loc[:, adm1_simple_cols], 'WB_GAD_ADM1'),\n",
    "    (merged_adm2.loc[:, adm2_simple_cols], 'WB_GAD_ADM2'),    \n",
    "    ]:\n",
    "    gdf, filename = file_def\n",
    "    # write geopackage to file\n",
    "    gdf.to_file(os.path.join(final_folder, \"gpkg\", f\"{filename}.gpkg\"), driver='GPKG')\n",
    "    # write shapefile to file\n",
    "    gdf.to_file(os.path.join(final_folder, \"shp\", f\"{filename}.shp\"), driver='ESRI Shapefile')\n",
    "    # Write geojson to file\n",
    "    gdf.to_file(os.path.join(final_folder, \"geojson\", f\"{filename}.geojson\"), driver='GeoJSON')\n",
    "\n",
    "pd.DataFrame(merged_adm1.loc[:, adm1_bad_cols]).to_csv(os.path.join(final_folder, 'WB_GAD_adm1_additional_columns.csv'), index=False)\n",
    "pd.DataFrame(merged_adm2.loc[:, adm2_bad_cols]).to_csv(os.path.join(final_folder, 'WB_GAD_adm2_additional_columns.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
