{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA/QC for delivered administrative boundaries\n",
    "The World Bank receives regular deliveries of official administrative boundaries. This script will process and evaluate these boundaries in several ways:\n",
    "\n",
    "- Combine the two ID columns into a single, primary key  \n",
    "  a. Check to ensure no duplicates in this new, primary key\n",
    "- Combine ADM0 file with disputed areas shapefile \n",
    "- Create ocean mask \n",
    "- Within higher heirarchical level, evaluate name duplication\n",
    "- Perform topological checks  \n",
    "  a. Ensure no overlaps  \n",
    "  b. Ensure no gaps  \n",
    "  c. Ensure all admin1 and admin2 shapes are fully contained within their heirarchical parents\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.geometry import Point, Polygon, box, shape\n",
    "from GOSTrocks.misc import tPrint\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from wb_gad_helper import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_folder = r'C:\\WBG\\Work\\data\\ADMIN\\NEW_WB_BOUNDS'\n",
    "out_folder = r'C:\\WBG\\Work\\data\\ADMIN\\QAQC'\n",
    "final_folder = os.path.join(admin_folder, 'FOR_PUBLICATION')\n",
    "if not os.path.exists(final_folder):\n",
    "    os.makedirs(final_folder)\n",
    "for file_format in ['gpkg', 'shp', 'geojson']:\n",
    "    temp_folder = os.path.join(final_folder, file_format)\n",
    "    if not os.path.exists(temp_folder):\n",
    "        os.makedirs(temp_folder)\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "admin0_file = os.path.join(admin_folder, 'WB_GAD_ADM0.shp')\n",
    "adm0_disputes_file = os.path.join(admin_folder, 'WB_GAD_NDLSA.shp')\n",
    "admin1_file = os.path.join(admin_folder, 'WB_GAD_ADM1.shp')\n",
    "admin2_file = os.path.join(admin_folder, 'WB_GAD_ADM2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm0 = gpd.read_file(admin0_file)\n",
    "adm0_disputes = gpd.read_file(adm0_disputes_file)\n",
    "adm1 = gpd.read_file(admin1_file)\n",
    "adm2 = gpd.read_file(admin2_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISO_A3</th>\n",
       "      <th>ISO_A2</th>\n",
       "      <th>WB_A3</th>\n",
       "      <th>HASC_0</th>\n",
       "      <th>GAUL_0</th>\n",
       "      <th>WB_STATUS</th>\n",
       "      <th>SOVEREIGN</th>\n",
       "      <th>NAM_0</th>\n",
       "      <th>geometry</th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>WB_REGION</th>\n",
       "      <th>WB_INCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHN</td>\n",
       "      <td>CN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>CN</td>\n",
       "      <td>147295</td>\n",
       "      <td>Member State</td>\n",
       "      <td>CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>MULTIPOLYGON (((117.58675 38.59517, 117.58909 ...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>EAS</td>\n",
       "      <td>UMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JPN</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>JP</td>\n",
       "      <td>126</td>\n",
       "      <td>Member State</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>MULTIPOLYGON (((137.48411 34.67386, 137.46683 ...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>EAS</td>\n",
       "      <td>HIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KOR</td>\n",
       "      <td>KR</td>\n",
       "      <td>KOR</td>\n",
       "      <td>KR</td>\n",
       "      <td>202</td>\n",
       "      <td>Member State</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Republic of Korea</td>\n",
       "      <td>MULTIPOLYGON (((126.05363 36.19852, 126.05372 ...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>EAS</td>\n",
       "      <td>HIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRK</td>\n",
       "      <td>KP</td>\n",
       "      <td>PRK</td>\n",
       "      <td>KP</td>\n",
       "      <td>67</td>\n",
       "      <td>Non Member State</td>\n",
       "      <td>PRK</td>\n",
       "      <td>D. P. R. of Korea</td>\n",
       "      <td>MULTIPOLYGON (((126.95508 38.16282, 126.95184 ...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>EAS</td>\n",
       "      <td>LIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RUS</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>RU</td>\n",
       "      <td>204</td>\n",
       "      <td>Member State</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>MULTIPOLYGON (((130.61904 48.88019, 130.60659 ...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>ECS</td>\n",
       "      <td>UMC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ISO_A3 ISO_A2 WB_A3 HASC_0  GAUL_0         WB_STATUS SOVEREIGN  \\\n",
       "0    CHN     CN   CHN     CN  147295      Member State       CHN   \n",
       "1    JPN     JP   JPN     JP     126      Member State       JPN   \n",
       "2    KOR     KR   KOR     KR     202      Member State       KOR   \n",
       "3    PRK     KP   PRK     KP      67  Non Member State       PRK   \n",
       "4    RUS     RU   RUS     RU     204      Member State       RUS   \n",
       "\n",
       "                NAM_0                                           geometry  \\\n",
       "0               China  MULTIPOLYGON (((117.58675 38.59517, 117.58909 ...   \n",
       "1               Japan  MULTIPOLYGON (((137.48411 34.67386, 137.46683 ...   \n",
       "2   Republic of Korea  MULTIPOLYGON (((126.05363 36.19852, 126.05372 ...   \n",
       "3   D. P. R. of Korea  MULTIPOLYGON (((126.95508 38.16282, 126.95184 ...   \n",
       "4  Russian Federation  MULTIPOLYGON (((130.61904 48.88019, 130.60659 ...   \n",
       "\n",
       "  CONTINENT WB_REGION WB_INCOME  \n",
       "0      Asia       EAS       UMC  \n",
       "1      Asia       EAS       HIC  \n",
       "2      Asia       EAS       HIC  \n",
       "3      Asia       EAS       LIC  \n",
       "4    Europe       ECS       UMC  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add World Bank classifications to ADM0\n",
    "wb_classes = get_wb_classifications_strict(grouping_version=\"37.0\", region_version=\"2.0\", income_version=\"2.0\",)\n",
    "wb_classes.rename({'ISO3':'ISO_A3', 'REGION':'WB_REGION', 'INCOME':'WB_INCOME'}, inplace=True, axis=1)\n",
    "wb_classes['CONTINENT'] = wb_classes['CONTINENT'].fillna(\"001\")\n",
    "continent_names_map = {\n",
    "    '002':'Africa',\n",
    "    '005':'South America',\n",
    "    '009':'Oceania',\n",
    "    '142':'Asia',\n",
    "    '150':'Europe',\n",
    "    '001':'North America'\n",
    "}\n",
    "wb_classes['CONTINENT'] = wb_classes['CONTINENT'].map(continent_names_map)\n",
    "\n",
    "adm0.drop(\"WB_REGION\", axis=1, inplace=True)\n",
    "adm0 = pd.merge(adm0, wb_classes, on='ISO_A3')\n",
    "adm0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_adm1 = merge_id_columns(adm1, [['P_CODE_1', 'P_CODE_1_t'], ['ADM1CD', 'ADM1CD_t']])\n",
    "merged_adm2 = merge_id_columns(adm2, [['P_CODE_1', 'P_CODE_1_t'], ['P_CODE_2', 'P_CODE_2_t'], ['ADM1CD', 'ADM1CD_t'], ['ADM2CD', 'ADM2CD_t']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADM1CD_c duplicates: 0\n",
      "ADM2CD_c duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in ADM1\n",
    "test_col = 'ADM1CD_c'\n",
    "check_duplicates(merged_adm1, test_col, os.path.join(out_folder, f'adm1_duplicates_{test_col}.gpkg'))\n",
    "\n",
    "# Check for duplicates in ADM2\n",
    "test_col = 'ADM2CD_c'\n",
    "check_duplicates(merged_adm2, test_col, os.path.join(out_folder, f'adm2_duplicates_{test_col}.gpkg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ADM0 with disputed territories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in adm0_disputes.columns:\n",
    "    if not col in adm0.columns:\n",
    "        adm0_disputes.drop(columns=[col], inplace=True)\n",
    "adm0_disputes.head()\n",
    "adm0_complete = pd.concat([adm0, adm0_disputes], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a global ocean mask from the admin divisions\n",
    "ocean_polygon = box(-180, -90, 180, 90)  # Global bounding box for ocean\n",
    "#clip ocean polygon to adm0 boundaries\n",
    "ocean_polygon = ocean_polygon.difference(adm0_complete.union_all())  # Remove land areas\n",
    "ocean_mask = gpd.GeoDataFrame([[1, ocean_polygon]], columns=['id', 'geometry'], crs=4326)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate name duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate duplicate names in adm1 and adm2\n",
    "evaluate_duplicate_names(merged_adm1, 'NAM_1', 'ISO_A3', os.path.join(out_folder, \"ADM1_name_duplicates.log\"))\n",
    "# Evaluate duplicate names in adm1 and adm2\n",
    "evaluate_duplicate_names(merged_adm2, 'NAM_2', 'ADM1CD_c', os.path.join(out_folder, \"ADM2_name_duplicates.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsj = gpd.sjoin(adm0, adm0, how=\"inner\", predicate=\"overlaps\", lsuffix=\"left\", rsuffix=\"right\")\\nsj = sj[sj.index != sj.index_right]\\n\\nsj[\\'intersection_geom\\'] = sj[\\'geometry_left\\'].intersection(sj[\\'geometry_right\\'])\\nsj[\\'intersection_area\\'] = sj[\\'intersection_geom\\'].area\\nsj\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use sjoin to identify overlapping polygons\n",
    "'''\n",
    "sj = gpd.sjoin(adm0, adm0, how=\"inner\", predicate=\"overlaps\", lsuffix=\"left\", rsuffix=\"right\")\n",
    "sj = sj[sj.index != sj.index_right]\n",
    "\n",
    "sj['intersection_geom'] = sj['geometry_left'].intersection(sj['geometry_right'])\n",
    "sj['intersection_area'] = sj['intersection_geom'].area\n",
    "sj\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate datasets into primary and secondary tables\n",
    "\n",
    "The delivered files contain several columns that are temporary or reference external sources. This section will separate the superfluous columns into a secondary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1_primary = 'ADM1CD_c'\n",
    "adm1_simple_cols = ['ISO_A3','ISO_A2','WB_A3','WB_REGION','WB_STATUS','NAM_0','NAM_1','ADM1CD_c','GEOM_SRCE', 'geometry']\n",
    "adm1_bad_cols = [adm1_primary] + [x for x in merged_adm1.columns if x not in adm1_simple_cols]\n",
    "\n",
    "adm2_primary = 'ADM2CD_c'\n",
    "adm2_simple_cols = adm1_simple_cols + ['NAM_2','ADM2CD_c']\n",
    "adm2_bad_cols = [adm2_primary] + [x for x in merged_adm2.columns if x not in adm2_simple_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out final versions in several data formats\n",
    "\n",
    "write out:\n",
    "- adm0 base\n",
    "- adm0 NDLSA\n",
    "- adm0 complete\n",
    "- adm1 simple\n",
    "- adm1 supplemntal columns\n",
    "- adm2 simple \n",
    "- adm2 supplemental columns\n",
    "\n",
    "in these formats\n",
    "- geopackage\n",
    "- geojson\n",
    "- shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:21:50\tcompleted WB_GAD_ocean_mask\n",
      "14:29:53\tcompleted WB_GAD_ADM0_complete\n",
      "14:38:26\tcompleted WB_GAD_ADM0\n",
      "14:38:28\tcompleted WB_GAD_ADM0_NDLSA\n",
      "14:43:47\tcompleted WB_GAD_ADM1\n",
      "15:06:02\tcompleted WB_GAD_ADM2\n",
      "15:06:04\tDissolving by CONTINENT\n",
      "15:08:43\tDissolving by WB_REGION\n"
     ]
    }
   ],
   "source": [
    "for file_def in [\n",
    "    (ocean_mask, 'WB_GAD_ocean_mask'),\n",
    "    (adm0_complete, 'WB_GAD_ADM0_complete'),\n",
    "    (adm0, 'WB_GAD_ADM0'),\n",
    "    (adm0_disputes, 'WB_GAD_ADM0_NDLSA'),\n",
    "    (merged_adm1.loc[:, adm1_simple_cols], 'WB_GAD_ADM1'),\n",
    "    (merged_adm2.loc[:, adm2_simple_cols], 'WB_GAD_ADM2'),    \n",
    "    ]:\n",
    "    gdf, filename = file_def\n",
    "    write_output(gdf, final_folder, filename)\n",
    "    tPrint(f\"completed {filename}\")\n",
    "# Save additional columns to CSV for reference\n",
    "pd.DataFrame(merged_adm1.loc[:, adm1_bad_cols]).to_csv(os.path.join(final_folder, 'WB_GAD_adm1_additional_columns.csv'), index=False)\n",
    "pd.DataFrame(merged_adm2.loc[:, adm2_bad_cols]).to_csv(os.path.join(final_folder, 'WB_GAD_adm2_additional_columns.csv'), index=False)\n",
    "\n",
    "# Generate dissolved continents and regions\n",
    "dissolve_folder = os.path.join(final_folder, 'REGIONS')\n",
    "if not os.path.exists(dissolve_folder):\n",
    "    os.makedirs(dissolve_folder)\n",
    "for col in ['CONTINENT', 'WB_REGION']:\n",
    "    if col in adm0_complete.columns:\n",
    "        tPrint(f\"Dissolving by {col}\")\n",
    "        dissolved = adm0_complete.dissolve(by=col, as_index=False)\n",
    "        # project results to equal-area projection\n",
    "        dissolved = dissolved.to_crs(epsg=8857)\n",
    "        dissolved.to_file(os.path.join(dissolve_folder, f\"WB_GAD_{col}.gpkg\"), driver='GPKG')\n",
    "tPrint(\"All output complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2s_ingest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
